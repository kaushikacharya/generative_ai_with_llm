# Generative AI with Large Language Models

## Course Info

- [URL](https://www.coursera.org/learn/generative-ai-with-llms)

## Course Contents

Chapter # |Chapter|
----------|-------|
1 |[Introduction to LLMs and generative AI project lifecycle](./notes/Chapter_1.md)|
2 | [LLM pre-training and scaling laws](./notes/Chapter_2.md)|
3 | [Fine-tuning LLMs with instruction](./notes/Chapter_3.md)|
4 | [Parameter Efficient Fine-Tuning](./notes/Chapter_4.md)|
5 | [Reinforcement Learning from Human Feedback](./notes/Chapter_5.md)|
6 | [LLM-powered applications](./notes/Chapter_6.md)|
7 | [Course conclusion and ongoing research](./notes/Chapter_7.md)|

## Lab assignments

Lab #|Assignment|Description|
-----|----------|-----------|
1    |[Generative AI Use Case: Summarize Dialogue](./notes/Chapter_1.md#lab-1---generative-ai-use-case-summarize-dialogue)|<ul><li>Perform prompt engineering</li><li>Compare zero shot, one shot and few shot inferences</ul>|
2    |[Fine-Tune a Generative AI Model for Dialogue Summarization](./notes/Chapter_4.md#lab-2---fine-tune-a-generative-ai-model-for-dialogue-summarization)|<ul><li>Perform full fine-tuning and PEFT</li><li>Evaluate results with ROUGE metrics</li></ul>|
3    |[Fine-Tune FLAN-T5 with Reinforcement Learning (PPO) and PEFT to Generate Less-Toxic Summaries](./notes/Chapter_5.md#lab-3---fine-tune-flan-t5-with-reinforcement-learning-to-generate-more-positive-summaries)|<ul><li>Fine-tune a FLAN-T5 model to generate less toxic summary</li><li>Use Meta AI's RoBERTa-based hate speech model for the reward model</li><li>Use Proximal Policy Optimization (PPO) to fine-tune and reduce the model's toxicity</li></ul>|

## FAQs

- [GenAI with LLMs lab FAQ](https://community.deeplearning.ai/t/genai-with-llms-lab-faq/374869)

## Lecture Notes

- [Notes](https://community.deeplearning.ai/t/genai-with-llms-lecture-notes/361913)

## Certificate

- [Course completion certificate](https://kaushikacharya.github.io/assets/certificates/Coursera_Certificate_Generative_AI_with_Large_Language_Models.pdf)
- Issued on Jan 2024
